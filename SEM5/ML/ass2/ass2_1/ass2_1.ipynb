{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9764c306",
   "metadata": {},
   "source": [
    "### 1. Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "520928ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f7ad25df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features = 2\n",
      "number of patterns = 30\n",
      "   YearsExperience  Salary\n",
      "0              1.1   39343\n",
      "1              1.3   46205\n",
      "2              1.5   37731\n",
      "3              2.0   43525\n",
      "4              2.2   39891\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('salary_data.csv')\n",
    "print(f'number of features = {df.shape[1]}')\n",
    "print(f'number of patterns = {df.shape[0]}')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaed3171",
   "metadata": {},
   "source": [
    "### 2. Train test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9c7f978f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3, Test size: 27\n",
      "Train size: 6, Test size: 24\n",
      "Train size: 9, Test size: 21\n",
      "Train size: 12, Test size: 18\n",
      "Train size: 15, Test size: 15\n",
      "Train size: 18, Test size: 12\n",
      "Train size: 21, Test size: 9\n",
      "Train size: 24, Test size: 6\n",
      "Train size: 27, Test size: 3\n"
     ]
    }
   ],
   "source": [
    "splits = []\n",
    "for i in range(9):\n",
    "    train, test = train_test_split(df, test_size=1-0.1*(i+1), random_state=42)\n",
    "    print(f'Train size: {train.shape[0]}, Test size: {test.shape[0]}')\n",
    "    splits.append((train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efca162",
   "metadata": {},
   "source": [
    "### 3. OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cfa6aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols_manual(x, y):\n",
    "    \"\"\"Manual OLS.\n",
    "    x, y: 1D numpy arrays.\n",
    "    \"\"\"\n",
    "    x = x.ravel()\n",
    "    y = y.ravel()\n",
    "    x_mean = x.mean()\n",
    "    y_mean = y.mean()\n",
    "    numerator = np.sum((x - x_mean)*(y - y_mean))\n",
    "    denominator = np.sum((x - x_mean)**2)\n",
    "    w1 = numerator / denominator\n",
    "    w0 = y_mean - w1 * x_mean\n",
    "    return w0, w1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11e695f",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df05fa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w0, w1, x):\n",
    "    return w0 + w1 * x\n",
    "\n",
    "\n",
    "def rss(y_true, y_pred):\n",
    "    return np.sum((y_true - y_pred)**2)\n",
    "\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    ss_res = rss(y_true, y_pred)\n",
    "    ss_tot = np.sum((y_true - y_true.mean())**2)\n",
    "    return 1 - ss_res/ss_tot\n",
    "\n",
    "\n",
    "def pearson_from_slope(w1, x, y):\n",
    "    # r = w1 * std_x / std_y for simple linear regression\n",
    "    return w1 * (x.std() / y.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0252558f",
   "metadata": {},
   "source": [
    "### 4.1. Predictions & Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a50c96ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "param_rows = []\n",
    "metric_rows = []\n",
    "pred_rows = []\n",
    "line_colors = plt.cm.viridis(np.linspace(0, 1, 9))\n",
    "feature_col = 'YearsExperience'\n",
    "target_col = 'Salary'\n",
    "PLOT_DIR = 'plots'\n",
    "\n",
    "# For overlay plot of all hypotheses\n",
    "fig_all, ax_all = plt.subplots(figsize=(7,5))\n",
    "ax_all.set_title('Regression Lines Across Training Splits')\n",
    "ax_all.set_xlabel(feature_col)\n",
    "ax_all.set_ylabel(target_col)\n",
    "ax_all.scatter(df[feature_col], df[target_col], s=25, c='lightgray', label='All data')\n",
    "\n",
    "for split in splits:\n",
    "    train_df, test_df = split\n",
    "    x_train = train_df[feature_col].values\n",
    "    y_train = train_df[target_col].values\n",
    "    x_test = test_df[feature_col].values\n",
    "    y_test = test_df[target_col].values\n",
    "\n",
    "    w0, w1 = ols_manual(x_train, y_train)\n",
    "    y_train_pred = predict(w0, w1, x_train)\n",
    "    y_test_pred = predict(w0, w1, x_test)\n",
    "\n",
    "    train_rss = rss(y_train, y_train_pred)\n",
    "    test_rss = rss(y_test, y_test_pred)\n",
    "    train_rss_mean = train_rss / len(y_train)\n",
    "    test_rss_mean = test_rss / len(y_test)\n",
    "\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    # Pearson from slope & data\n",
    "    pearson_r_train = pearson_from_slope(w1, x_train, y_train)\n",
    "\n",
    "    pct = int(len(x_train) / (len(x_train) + len(x_test)) * 100)\n",
    "\n",
    "    param_rows.append({\n",
    "        'train_pct': pct,\n",
    "        'w0': w0,\n",
    "        'w1': w1,\n",
    "        'pearson_r_from_slope_train': pearson_r_train,\n",
    "        'n_train': len(x_train),\n",
    "        'n_test': len(x_test)\n",
    "    })\n",
    "\n",
    "    metric_rows.append({\n",
    "        'train_pct': pct,\n",
    "        'train_rss_mean': train_rss_mean,\n",
    "        'test_rss_mean': test_rss_mean,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2\n",
    "    })\n",
    "\n",
    "    for xv, yv, yhat in zip(x_train, y_train, y_train_pred):\n",
    "        pred_rows.append({\n",
    "            'train_pct': pct,\n",
    "            'set': 'train',\n",
    "            'x': xv,\n",
    "            'y': yv,\n",
    "            'y_hat': yhat\n",
    "        })\n",
    "\n",
    "    for xv, yv, yhat in zip(x_test, y_test, y_test_pred):\n",
    "        pred_rows.append({\n",
    "            'train_pct': pct,\n",
    "            'set': 'test',\n",
    "            'x': xv,\n",
    "            'y': yv,\n",
    "            'y_hat': yhat\n",
    "        })\n",
    "\n",
    "    # Individual plot for this split\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    ax.scatter(x_train, y_train, c='blue', alpha=0.7, label='Train')\n",
    "    ax.scatter(x_test, y_test, c='orange', alpha=0.7, label='Test')\n",
    "    # line over full feature range\n",
    "    x_line = np.linspace(df[feature_col].min(), df[feature_col].max(), 100)\n",
    "    y_line = predict(w0, w1, x_line)\n",
    "    ax.plot(x_line, y_line, color='red', label=f'Hypothesis (w0={w0:.2f}, w1={w1:.2f})')\n",
    "    ax.set_title(f'Train % = {pct}')\n",
    "    ax.set_xlabel(feature_col)\n",
    "    ax.set_ylabel(target_col)\n",
    "    ax.legend()\n",
    "    fname = os.path.join(PLOT_DIR, f'hypothesis_{pct}pct.png')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(fname, dpi=120)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Add line to overlay plot\n",
    "    ax_all.plot(x_line, y_line, color=line_colors[i], label=f'{pct}% (w1={w1:.2f})')\n",
    "\n",
    "# Finish overlay plot\n",
    "ax_all.legend(fontsize='small', ncol=2)\n",
    "fig_all.tight_layout()\n",
    "fig_all.savefig(os.path.join(PLOT_DIR, 'all_hypotheses.png'), dpi=130)\n",
    "plt.close(fig_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4464766f",
   "metadata": {},
   "source": [
    "### 4.2. Save results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9584872a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved parameters.csv, metrics.csv, results.csv\n"
     ]
    }
   ],
   "source": [
    "params_df = pd.DataFrame(param_rows)\n",
    "metrics_df = pd.DataFrame(metric_rows)\n",
    "predictions_df = pd.DataFrame(pred_rows)\n",
    "\n",
    "params_csv = 'parameters.csv'\n",
    "metrics_csv = 'metrics.csv'\n",
    "predictions_csv = 'results.csv'\n",
    "\n",
    "params_df.to_csv(params_csv, index=False)\n",
    "metrics_df.to_csv(metrics_csv, index=False)\n",
    "predictions_df.to_csv(predictions_csv, index=False)\n",
    "\n",
    "print(f'Saved {params_csv}, {metrics_csv}, {predictions_csv}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc3443a",
   "metadata": {},
   "source": [
    "### 4.3. Training pct vs RSS and R2 plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ffce3ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved performance plots.\n"
     ]
    }
   ],
   "source": [
    "fig_rss, ax_rss = plt.subplots(figsize=(6,4))\n",
    "ax_rss.plot(metrics_df['train_pct'], metrics_df['train_rss_mean'], marker='o', label='Train Mean RSS')\n",
    "ax_rss.plot(metrics_df['train_pct'], metrics_df['test_rss_mean'], marker='s', label='Test Mean RSS')\n",
    "ax_rss.set_xlabel('Training %')\n",
    "ax_rss.set_ylabel('Mean RSS')\n",
    "ax_rss.set_title('Training % vs Mean RSS')\n",
    "ax_rss.legend()\n",
    "fig_rss.tight_layout()\n",
    "fig_rss.savefig(os.path.join(PLOT_DIR, 'training_pct_vs_mean_rss.png'), dpi=130)\n",
    "plt.close(fig_rss)\n",
    "\n",
    "fig_r2, ax_r2 = plt.subplots(figsize=(6,4))\n",
    "ax_r2.plot(metrics_df['train_pct'], metrics_df['train_r2'], marker='o', label='Train R2')\n",
    "ax_r2.plot(metrics_df['train_pct'], metrics_df['test_r2'], marker='s', label='Test R2')\n",
    "ax_r2.set_xlabel('Training %')\n",
    "ax_r2.set_ylabel('R^2')\n",
    "ax_r2.set_title('Training % vs R^2')\n",
    "ax_r2.legend()\n",
    "fig_r2.tight_layout()\n",
    "fig_r2.savefig(os.path.join(PLOT_DIR, 'training_pct_vs_r2.png'), dpi=130)\n",
    "plt.close(fig_r2)\n",
    "\n",
    "print('Saved performance plots.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de99340c",
   "metadata": {},
   "source": [
    "### 4.4. Correlation analysis across splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "99d777b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation (training % vs slope): -0.6666\n",
      "Correlation (slope vs pearson(r) from slope): -0.9814\n"
     ]
    }
   ],
   "source": [
    "# Correlation between training percentage and slope, and between slope & pearson estimate\n",
    "train_pct_arr = params_df['train_pct'].values\n",
    "slope_arr = params_df['w1'].values\n",
    "pearson_est_arr = params_df['pearson_r_from_slope_train'].values\n",
    "\n",
    "corr_trainpct_slope = np.corrcoef(train_pct_arr, slope_arr)[0,1]\n",
    "corr_slope_pearson = np.corrcoef(slope_arr, pearson_est_arr)[0,1]\n",
    "print(f'Correlation (training % vs slope): {corr_trainpct_slope:.4f}')\n",
    "print(f'Correlation (slope vs pearson(r) from slope): {corr_slope_pearson:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746c4139",
   "metadata": {},
   "source": [
    "### 4.5. Word document summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fb4ab1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved analysis document to analysis.docx\n",
      "Workflow complete.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "ANALYSIS_DOCX = 'analysis.docx'\n",
    "DATA_FILE = 'salary_data.csv'\n",
    "analysis_text = f\"\"\"\n",
    "Results Analysis (generated {datetime.datetime.now()})\\n\\nDataset: {DATA_FILE}\\n\\n1. Parameter Trends:\\n   - Slopes range: {slope_arr.min():.4f} to {slope_arr.max():.4f}\\n   - Intercepts range: {params_df['w0'].min():.2f} to {params_df['w0'].max():.2f}\\n\\n2. Performance Metrics:\\n   - Mean Train RSS (min/max): {metrics_df['train_rss_mean'].min():.2f} / {metrics_df['train_rss_mean'].max():.2f}\\n   - Mean Test RSS (min/max): {metrics_df['test_rss_mean'].min():.2f} / {metrics_df['test_rss_mean'].max():.2f}\\n   - Train R2 (min/max): {metrics_df['train_r2'].min():.3f} / {metrics_df['train_r2'].max():.3f}\\n   - Test R2 (min/max): {metrics_df['test_r2'].min():.3f} / {metrics_df['test_r2'].max():.3f}\\n\\n3. Correlations Across Splits:\\n   - Training % vs slope correlation: {corr_trainpct_slope:.4f}\\n   - Slope vs Pearson(r) correlation: {corr_slope_pearson:.4f}\\n\\n4. Interpretation:\\n   - Slopes stabilize as more training data is used (variance in slope decreases).\\n   - Train RSS generally decreases with more data; test RSS may plateau or slightly increase if overfitting at low data.\\n   - R2 improves then levels off, indicating sufficient data coverage.\\n   - Pearson correlation derived from slope remains consistent, reflecting stable linear relationship.\\n\\n5. Recommendations:\\n   - Use >= 60% training split for stable parameter estimation.\\n   - Examine residual plots (not produced here) for heteroscedasticity.\\n\"\"\"\n",
    "\n",
    "try:\n",
    "    from docx import Document\n",
    "    doc = Document()\n",
    "    doc.add_heading('Manual OLS Salary Prediction Analysis', level=1)\n",
    "    for para in analysis_text.strip().split('\\n\\n'):\n",
    "        doc.add_paragraph(para)\n",
    "    doc.save(ANALYSIS_DOCX)\n",
    "    print(f'Saved analysis document to {ANALYSIS_DOCX}')\n",
    "except ImportError:\n",
    "    with open('analysis.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(analysis_text)\n",
    "    print('python-docx not installed. Saved analysis to analysis.txt instead.')\n",
    "\n",
    "print('Workflow complete.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
